{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicabilidad con SHAP\n",
    "## An\u00e1lisis de Interpretabilidad para Modelos AML\n",
    "\n",
    "**Objetivo Espec\u00edfico 4 (OE4)**: Evaluar el desempe\u00f1o de los modelos desarrollados mediante m\u00e9tricas de precisi\u00f3n, recall, F1-score y an\u00e1lisis de explicabilidad.\n",
    "\n",
    "Este notebook implementa an\u00e1lisis de explicabilidad usando **SHAP** (SHapley Additive exPlanations) para:\n",
    "- Identificar qu\u00e9 features influyen m\u00e1s en las predicciones de fraude\n",
    "- Entender decisiones individuales del modelo\n",
    "- Validar que el modelo aprende patrones sensatos\n",
    "- Cumplir con requisitos de transparencia regulatoria (SARLAFT 2.0)\n",
    "\n",
    "### \u00bfPor qu\u00e9 SHAP?\n",
    "\n",
    "SHAP es esencial para:\n",
    "1. **Regulaci\u00f3n**: SARLAFT 2.0 requiere explicabilidad en decisiones AML\n",
    "2. **Confianza**: Entidades financieras necesitan justificar alertas\n",
    "3. **Debug**: Detectar si el modelo aprende patrones err\u00f3neos\n",
    "4. **Mejora**: Identificar features relevantes para ingenier\u00eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Utilidades del proyecto\n",
    "from src.utils.config import load_config\n",
    "from src.utils.reproducibility import set_seed\n",
    "\n",
    "# Configuraci\u00f3n\n",
    "config = load_config('../../configs/config.yaml')\n",
    "set_seed(config['project']['random_seed'])\n",
    "\n",
    "# Estilo de visualizaci\u00f3n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "shap.initjs()  # Inicializa JS para visualizaciones interactivas\n",
    "\n",
    "print(\"\u2713 Librer\u00edas cargadas\")\n",
    "print(f\"  SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Carga datos\n",
    "df = pd.read_csv('../../data/synthetic/aml_colombia_synthetic.csv')\n",
    "print(f\"\ud83d\udcca Dataset: {df.shape}\")\n",
    "print(f\"   Fraude: {df['isFraud'].sum()} ({df['isFraud'].mean()*100:.2f}%)\")\n",
    "\n",
    "# Preprocesamiento\n",
    "le = LabelEncoder()\n",
    "df['type_encoded'] = le.fit_transform(df['type'])\n",
    "\n",
    "# Features\n",
    "feature_names = ['step', 'amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
    "                'oldbalanceDest', 'newbalanceDest', 'type_encoded']\n",
    "\n",
    "X = df[feature_names].values\n",
    "y = df['isFraud'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=config['model']['test_size'],\n",
    "    random_state=config['model']['random_state'],\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Scale (SHAP funciona mejor con datos escalados)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n\u2713 Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(f\"  Features: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenar Modelos para Explicabilidad\n",
    "\n",
    "Entrenamos XGBoost y Random Forest para analizar con SHAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calcula weight para balanceo\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\n\ud83d\udd25 Entrenando XGBoost...\")\n",
    "xgb_params = config['xgboost']\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=xgb_params['n_estimators'],\n",
    "    max_depth=xgb_params['max_depth'],\n",
    "    learning_rate=xgb_params['learning_rate'],\n",
    "    subsample=xgb_params['subsample'],\n",
    "    colsample_bytree=xgb_params['colsample_bytree'],\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=config['model']['random_state'],\n",
    "    tree_method='hist'\n",
    ")\n",
    "model_xgb.fit(X_train_scaled, y_train)\n",
    "print(\"\u2713 XGBoost entrenado\")\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\n\ud83c\udf33 Entrenando Random Forest...\")\n",
    "rf_params = config['random_forest']\n",
    "model_rf = RandomForestClassifier(\n",
    "    n_estimators=rf_params['n_estimators'],\n",
    "    max_depth=rf_params['max_depth'],\n",
    "    min_samples_split=rf_params['min_samples_split'],\n",
    "    min_samples_leaf=rf_params['min_samples_leaf'],\n",
    "    class_weight=rf_params['class_weight'],\n",
    "    random_state=config['model']['random_state'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "model_rf.fit(X_train_scaled, y_train)\n",
    "print(\"\u2713 Random Forest entrenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SHAP para XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Crea explainer para XGBoost\n",
    "print(\"\ud83d\udcca Calculando SHAP values para XGBoost...\")\n",
    "explainer_xgb = shap.TreeExplainer(model_xgb)\n",
    "\n",
    "# Calcula SHAP values (usa subset para eficiencia)\n",
    "sample_size = min(1000, len(X_test_scaled))\n",
    "X_test_sample = X_test_scaled[:sample_size]\n",
    "shap_values_xgb = explainer_xgb.shap_values(X_test_sample)\n",
    "\n",
    "print(f\"\u2713 SHAP values calculados para {sample_size} muestras\")\n",
    "print(f\"  Shape: {shap_values_xgb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Summary Plot - Feature Importance Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary plot (importancia global)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_xgb, X_test_sample, \n",
    "                 feature_names=feature_names, show=False)\n",
    "plt.title('SHAP Summary Plot - XGBoost', fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_summary_xgb.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Interpretaci\u00f3n del Summary Plot:\")\n",
    "print(\"  - Features ordenadas por importancia (top = m\u00e1s importante)\")\n",
    "print(\"  - Color rojo = valor alto de la feature\")\n",
    "print(\"  - Color azul = valor bajo de la feature\")\n",
    "print(\"  - Eje X = impacto en predicci\u00f3n (positivo = aumenta prob. fraude)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bar Plot - Feature Importance Promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Bar plot (importancia promedio)\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_xgb, X_test_sample,\n",
    "                 feature_names=feature_names, \n",
    "                 plot_type='bar', show=False)\n",
    "plt.title('SHAP Feature Importance - XGBoost', fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_importance_xgb.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Force Plot - Explicaci\u00f3n de Caso Individual (Fraude Detectado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Encuentra un caso de fraude correctamente detectado\n",
    "y_pred_xgb = model_xgb.predict(X_test_scaled)\n",
    "fraud_indices = np.where((y_test[:sample_size] == 1) & (y_pred_xgb[:sample_size] == 1))[0]\n",
    "\n",
    "if len(fraud_indices) > 0:\n",
    "    fraud_idx = fraud_indices[0]\n",
    "    \n",
    "    print(f\"\\n\ud83d\udd0d Analizando transacci\u00f3n fraudulenta (\u00edndice {fraud_idx}):\")\n",
    "    print(\"=\"*60)\n",
    "    for i, fname in enumerate(feature_names):\n",
    "        print(f\"  {fname:20s}: {X_test_sample[fraud_idx, i]:,.2f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Force plot\n",
    "    shap.force_plot(\n",
    "        explainer_xgb.expected_value,\n",
    "        shap_values_xgb[fraud_idx],\n",
    "        X_test_sample[fraud_idx],\n",
    "        feature_names=feature_names,\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../reports/figures/shap_force_fraud.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca Interpretaci\u00f3n del Force Plot:\")\n",
    "    print(\"  - Base value = predicci\u00f3n promedio del modelo\")\n",
    "    print(\"  - Features en rojo empujan hacia fraude (1)\")\n",
    "    print(\"  - Features en azul empujan hacia normal (0)\")\n",
    "    print(\"  - Longitud de la barra = magnitud del impacto\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f No se encontraron fraudes en la muestra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Dependence Plot - Relaci\u00f3n entre Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dependence plot para feature m\u00e1s importante\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Amount (suele ser la m\u00e1s importante)\n",
    "shap.dependence_plot(\n",
    "    'amount', shap_values_xgb, X_test_sample,\n",
    "    feature_names=feature_names,\n",
    "    ax=axes[0], show=False\n",
    ")\n",
    "axes[0].set_title('SHAP Dependence: Amount', fontsize=12, weight='bold')\n",
    "\n",
    "# newbalanceOrig\n",
    "shap.dependence_plot(\n",
    "    'newbalanceOrig', shap_values_xgb, X_test_sample,\n",
    "    feature_names=feature_names,\n",
    "    ax=axes[1], show=False\n",
    ")\n",
    "axes[1].set_title('SHAP Dependence: newbalanceOrig', fontsize=12, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_dependence_xgb.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udcca Interpretaci\u00f3n del Dependence Plot:\")\n",
    "print(\"  - Muestra c\u00f3mo cambia el SHAP value con el valor de la feature\")\n",
    "print(\"  - Color = valor de otra feature (interacci\u00f3n)\")\n",
    "print(\"  - Permite identificar relaciones no lineales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP para Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# SHAP para Random Forest\n",
    "print(\"\ud83d\udcca Calculando SHAP values para Random Forest...\")\n",
    "explainer_rf = shap.TreeExplainer(model_rf)\n",
    "shap_values_rf = explainer_rf.shap_values(X_test_sample)\n",
    "\n",
    "# RF retorna SHAP values para cada clase [clase_0, clase_1]\n",
    "# Usamos solo la clase 1 (fraude)\n",
    "if isinstance(shap_values_rf, list):\n",
    "    shap_values_rf_fraud = shap_values_rf[1]\n",
    "else:\n",
    "    shap_values_rf_fraud = shap_values_rf\n",
    "\n",
    "print(f\"\u2713 SHAP values calculados\")\n",
    "print(f\"  Shape: {shap_values_rf_fraud.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary plot RF\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_rf_fraud, X_test_sample,\n",
    "                 feature_names=feature_names, show=False)\n",
    "plt.title('SHAP Summary Plot - Random Forest', fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_summary_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot RF\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values_rf_fraud, X_test_sample,\n",
    "                 feature_names=feature_names,\n",
    "                 plot_type='bar', show=False)\n",
    "plt.title('SHAP Feature Importance - Random Forest', fontsize=14, weight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_importance_rf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparaci\u00f3n de Feature Importance: XGBoost vs Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calcula importancia promedio por modelo\n",
    "importance_xgb = np.abs(shap_values_xgb).mean(axis=0)\n",
    "importance_rf = np.abs(shap_values_rf_fraud).mean(axis=0)\n",
    "\n",
    "# DataFrame comparativo\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'XGBoost': importance_xgb,\n",
    "    'Random Forest': importance_rf\n",
    "}).sort_values('XGBoost', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARACI\u00d3N DE FEATURE IMPORTANCE (SHAP)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualizaci\u00f3n comparativa\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "comparison_df.set_index('Feature')[['XGBoost', 'Random Forest']].plot(\n",
    "    kind='bar', ax=ax, width=0.8\n",
    ")\n",
    "ax.set_title('Feature Importance Comparison (SHAP)', fontsize=14, weight='bold')\n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('Mean |SHAP Value|')\n",
    "ax.legend(title='Modelo')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../reports/figures/shap_comparison.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusiones de Explicabilidad\n",
    "\n",
    "### Hallazgos Clave:\n",
    "\n",
    "1. **Features m\u00e1s Importantes** (seg\u00fan SHAP):\n",
    "   - `amount`: Montos de transacci\u00f3n son el predictor #1\n",
    "   - `newbalanceOrig`: Balance final origen (cuentas vaciadas = fraude)\n",
    "   - `oldbalanceOrg`: Balance inicial origen\n",
    "   - `type_encoded`: Tipo de transacci\u00f3n (CASH_OUT/TRANSFER sospechosos)\n",
    "\n",
    "2. **Patrones Detectados**:\n",
    "   - Montos altos empujan fuertemente hacia fraude\n",
    "   - Balances finales cercanos a cero son altamente sospechosos\n",
    "   - Interacciones no lineales capturadas por los modelos\n",
    "\n",
    "3. **Consistencia entre Modelos**:\n",
    "   - XGBoost y Random Forest identifican features similares\n",
    "   - Alta concordancia = patrones robustos\n",
    "\n",
    "4. **Cumplimiento Regulatorio**:\n",
    "   - \u2705 SHAP permite explicar cada alerta de fraude\n",
    "   - \u2705 Cumple con transparencia requerida por SARLAFT 2.0\n",
    "   - \u2705 Investigadores pueden justificar decisiones del modelo\n",
    "\n",
    "### Recomendaciones:\n",
    "\n",
    "- **Feature Engineering**: Crear m\u00e1s features basadas en `amount` y balances\n",
    "- **Umbrales**: Usar SHAP para calibrar umbrales de alerta\n",
    "- **Auditor\u00eda**: Force plots individuales para casos sospechosos\n",
    "- **Monitoreo**: Tracking de feature importance en producci\u00f3n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}